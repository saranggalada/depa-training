{
    "pipeline": [
      {
        "name": "TextJoin",
        "config": {
          "datasets": [
            {
              "id": "19517ba8-bab8-11ed-afa1-0242ac120002",
              "name": "medqa",
              "file": "medical-question-answering-datasets.csv",
              "select_variables": ["input", "output"],
              "num_rows": 200,
              "mount_path": "/mnt/remote/medqa/"
            },
            {
              "id": "216d5cc6-bab8-11ed-afa1-0242ac120002",
              "name": "chatdoctor",
              "file": "ChatDoctor-HealthCareMagic-100k.csv",
              "select_variables": ["input", "output"],
              "num_rows": 200,
              "mount_path": "/mnt/remote/chatdoctor/"
            },
            {
              "id": "2830a144-bab8-11ed-afa1-0242ac120002",
              "name": "medquad",
              "file": "MedQuad-MedicalQnADataset.csv",
              "select_variables": ["Question", "Answer"],
              "num_rows": 200,
              "mount_path": "/mnt/remote/medquad/"
            }
          ],
          "joined_dataset": {
            "output_folder": "/tmp/",
            "output_file": "medqa_chatdoctor_medquad_joined.csv"
          }
        }
      },
      {
        "name": "PrivateLLMFineTune",
        "config": {
          "device": "cpu",
          "saved_model_dir": "/mnt/model/",
          "model_name": "meta-llama/Llama-3.2-1b",
          "trained_model_output_path": "/mnt/remote/output/model.pth",
          "input_dataset_path": "/tmp/medqa_chatdoctor_medquad_joined.csv",
          "HF_READ_TOKEN": "",
          "HF_WRITE_TOKEN": "",
          "SAVE_MODEL_REPO_NAME": "Sarang-Galada/medqa-dp-llm-finetune-test_8Feb25",
          "MAX_TOKENS": 512,
          "BATCH_SIZE": 4,
          "NUM_EPOCHS": 1,
          "Q_PRECISION": "load_in_4bit",
          "LEARNING_RATE": 5e-5,
          "EPSILON": 7.5,
          "DELTA": 1e-5,
          "MAX_GRAD_NORM": 1.0,
          "MAX_PHYSICAL_BATCH_SIZE": 4,
          "LORA_RANK": 8,
          "LORA_ALPHA": 32,
          "LORA_TARGET_MODULES": ["q_proj", "v_proj"],
          "LORA_DROPOUT": 0.05,
          "LORA_BIAS": null,
          "LOG_FREQ_STEPS": 50
        }
      }
    ]
  }
  